{"cells":[{"cell_type":"code","source":["%fs ls /mnt/sf_open_data/fire_dept_calls_for_service/"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Iniciamos spark\nspark"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Creamos un dataframe a partir del CSV\nmyDF = spark.read.csv('/mnt/sf_open_data/fire_dept_calls_for_service/Fire_Department_Calls_for_Service.csv', header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Quitamos los espacios de los nombres para que no haya errrores\n\nschema = StructType([StructField('CallNumber', IntegerType(), True),\n                     StructField('UnitID', StringType(), True),\n                     StructField('IncidentNumber', IntegerType(), True),\n                     StructField('CallType', StringType(), True),                  \n                     StructField('CallDate', StringType(), True),       \n                     StructField('WatchDate', StringType(), True),       \n                     StructField('ReceivedDtTm', StringType(), True),       \n                     StructField('EntryDtTm', StringType(), True),       \n                     StructField('DispatchDtTm', StringType(), True),       \n                     StructField('ResponseDtTm', StringType(), True),       \n                     StructField('OnSceneDtTm', StringType(), True),       \n                     StructField('TransportDtTm', StringType(), True),                  \n                     StructField('HospitalDtTm', StringType(), True),       \n                     StructField('CallFinalDisposition', StringType(), True),       \n                     StructField('AvailableDtTm', StringType(), True),       \n                     StructField('Address', StringType(), True),       \n                     StructField('City', StringType(), True),       \n                     StructField('ZipcodeofIncident', IntegerType(), True),       \n                     StructField('Battalion', StringType(), True),                 \n                     StructField('StationArea', StringType(), True),       \n                     StructField('Box', StringType(), True),       \n                     StructField('OriginalPriority', StringType(), True),       \n                     StructField('Priority', StringType(), True),       \n                     StructField('FinalPriority', IntegerType(), True),       \n                     StructField('ALSUnit', BooleanType(), True),       \n                     StructField('CallTypeGroup', StringType(), True),\n                     StructField('NumberofAlarms', IntegerType(), True),\n                     StructField('UnitType', StringType(), True),\n                     StructField('Unitsequenceincalldispatch', IntegerType(), True),\n                     StructField('FirePreventionDistrict', StringType(), True),\n                     StructField('SupervisorDistrict', StringType(), True),\n                     StructField('NeighborhoodDistrict', StringType(), True),\n                     StructField('Location', StringType(), True),\n                     StructField('RowID', StringType(), True)])"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Cambiamos el esquema del dataframe al que acabamos de hacer nosotros\nmyDF = spark.read.csv('/mnt/sf_open_data/fire_dept_calls_for_service/Fire_Department_Calls_for_Service.csv', header=True, schema=schema)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Mostramos las primeras 5 columnas\ndisplay(myDF.limit(5))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Vemos las columnas\nmyDF.columns"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#Miramos el numero total de registros del dataframe\nmyDF.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Vemos los tipos de llamadas de las primeras 5 columnas\nmyDF.select('CallType').show(5)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Añadimos el distinct para mostrar solo los tipos de llamadas distintos\nmyDF.select('CallType').distinct().show(35, False)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#Vemos cuantos casos hay de cada tipo de llamada\ndisplay(myDF.select('CallType').groupBy('CallType').count().orderBy(\"count\", ascending=False).limit(7))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Mostramos el esquema\nmyDF.printSchema()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Transformamos a los tipos de fecha de Java\n\nfrom_pattern1 = 'MM/dd/yyyy'\nto_pattern1 = 'yyyy-MM-dd'\n\nfrom_pattern2 = 'MM/dd/yyyy hh:mm:ss aa'\nto_pattern2 = 'MM/dd/yyyy hh:mm:ss aa'\n\n\nmyDF=myDF \\\n  .withColumn('CallDateTS', unix_timestamp(myDF['CallDate'], from_pattern1).cast(\"timestamp\")) \\\n  .drop('CallDate') \\\n  .withColumn('WatchDateTS', unix_timestamp(myDF['WatchDate'], from_pattern1).cast(\"timestamp\")) \\\n  .drop('WatchDate') \\\n  .withColumn('ReceivedDtTmTS', unix_timestamp(myDF['ReceivedDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('ReceivedDtTm') \\\n  .withColumn('EntryDtTmTS', unix_timestamp(myDF['EntryDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('EntryDtTm') \\\n  .withColumn('DispatchDtTmTS', unix_timestamp(myDF['DispatchDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('DispatchDtTm') \\\n  .withColumn('ResponseDtTmTS', unix_timestamp(myDF['ResponseDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('ResponseDtTm') \\\n  .withColumn('OnSceneDtTmTS', unix_timestamp(myDF['OnSceneDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('OnSceneDtTm') \\\n  .withColumn('TransportDtTmTS', unix_timestamp(myDF['TransportDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('TransportDtTm') \\\n  .withColumn('HospitalDtTmTS', unix_timestamp(myDF['HospitalDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('HospitalDtTm') \\\n  .withColumn('AvailableDtTmTS', unix_timestamp(myDF['AvailableDtTm'], from_pattern2).cast(\"timestamp\")) \\\n  .drop('AvailableDtTm')  "],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Mostramos el esquema de nuevo y comprobamos que las fechas son timestamp en vez de string\nmyDF.printSchema()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#Mostramos las 5 primeras filas\ndisplay(myDF.limit(5))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Mostramos los años de los que tenemos datos \nmyDF.select(year('CallDateTS')).distinct().orderBy('year(CallDateTS)').show()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Mostramos los dias en los que más llamadas se han producido\nmyDF.filter(year('CallDateTS') == '2016').filter(dayofyear('CallDateTS') >= 0).groupBy(dayofyear('CallDateTS')).count().orderBy('count', ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["display(myDF.filter(year('CallDateTS') == '2016').filter(dayofyear('CallDateTS')<= 60).groupBy(dayofyear('CallDateTS')).count().orderBy('dayofyear(CallDateTS)'))"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Vamos a analizr el dia 37, 06-02-2016 \n#Mostramos el tipo de llamas que se realizaron ordenadas de mayor a menor.\nmyDF.filter(year('CallDateTS') == '2016').filter(dayofyear('CallDateTS') == 37).groupBy('CallType').count().orderBy('count', ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Vemos de que tipo son las llamadas\nmyDF.filter(year('CallDateTS') == '2016').groupBy('CallType').count().orderBy('count', ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Mostramos en que distrito se realizaron más llamadas.\n\ndisplay(myDF.filter(year('CallDateTS') == '2016').filter(dayofyear('CallDateTS') == 37).groupBy('NeighborhoodDistrict').count().orderBy('count', ascending=False))"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Vemos los barrios con más llamadas durante 2016\nmyDF.filter(year('CallDateTS') == '2016').groupBy('NeighborhoodDistrict').count().orderBy('count', ascending=False).show(20,False)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Mostramos un gráfico de la semana de antes y después del día 37\ndisplay(myDF.filter(year('CallDateTS') == '2016').filter(dayofyear('CallDateTS') >= 30 ).filter(dayofyear('CallDateTS') <= 44 ).groupBy(dayofyear('CallDateTS')).count().orderBy('dayofyear(CallDateTS)'))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Vemos el numero de particiones del dataframe\nmyDF.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#Reparticionamos a un multiplo de 3 para optimizar\nmyDF.repartition(6).createOrReplaceTempView(\"fireServiceVIEW\");"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["#Metemos la tabla a memoria para ejecutarlo mas rápidamente\nspark.catalog.cacheTable(\"fireServiceVIEW\")"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Materializamos el cache ya que hasta que no se llama a una transformación como count no se cambia\nspark.table(\"fireServiceVIEW\").count()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#Creamos un nuevo DataFrame con la vista que hemos creado\nfireServiceDF = spark.table(\"fireServiceVIEW\")"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# Ejecutamos count para ver cuanto tarda ahora\n\nfireServiceDF.count()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["#Comprobamos que la tabla esta en memoria\nspark.catalog.isCached(\"fireServiceVIEW\")"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["%fs ls /tmp/"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["#Guardamos la tabla como archivo parquet\nfireServiceDF.write.format('parquet').mode(\"overwrite\").save('/tmp/fireServiceParquetFinal/')"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["#Creamos un Dataframe leyendo directamente de ese archivo parquet\ntempDF = spark.read.parquet('/tmp/fireServiceParquetFinal/')"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Mostramos que el dataframe ha ingestado los datos correctamente\ndisplay(tempDF.limit(2))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["\n%sql SELECT count(*) FROM fireServiceVIEW;\n--También podemos hacer consultas mediante sql no solo mediante dataframes"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["%sql SELECT `NeighborhoodDistrict`, count(`NeighborhoodDistrict`) AS Neighborhood_Count FROM fireServiceVIEW WHERE year(`CallDateTS`) == '2016' GROUP BY `NeighborhoodDistrict` ORDER BY Neighborhood_Count DESC LIMIT 15;\n"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["%sql SELECT `CallTypeGroup`, count(`CallTypeGroup`) AS CallTypeGroup_Count FROM fireServiceVIEW WHERE year(`CallDateTS`) == '2015' GROUP BY `CallTypeGroup` ORDER BY CallTypeGroup_Count DESC;"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["%sql select count(*) from fireServiceVIEW where year(`CallDateTS`) == '2015'\n--147470/297724=0.49 casi el 50% de las llamadas son con riesgo de muerte"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#Vemos las particiones\nspark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["#Cambiamos las particiones a 6\nspark.conf.set(\"spark.sql.shuffle.partitions\", 6)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["#Comprobamos que efectivamente tenemos 6\nspark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["%sql DESC fireServiceVIEW;"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["%sql SELECT distinct hour(`ReceivedDtTmTS`) as hora, count( hour(`ReceivedDtTmTS`)) as cuenta FROM fireServiceVIEW WHERE year(`CallDateTS`)==2016 AND dayofyear(`CallDateTS`)=37 group by hour(`ReceivedDtTmTS`) order by hora ;\n--Vemos a que hora se registraron más llamadas el día 37"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["%sql SELECT distinct hour(`ReceivedDtTmTS`) as hora, count( hour(`ReceivedDtTmTS`)) as cuenta FROM fireServiceVIEW WHERE year(`CallDateTS`)==2016 group by hour(`ReceivedDtTmTS`) order by hora;\n--Mostramos a que horas se suelen producir más llamadas durante 2016 para comparar los resultados"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["%sql SELECT distinct hour(`ReceivedDtTmTS`) as hora, count( hour(`ReceivedDtTmTS`)) as cuenta FROM fireServiceVIEW WHERE dayofyear(`CallDateTS`)=1 group by hour(`ReceivedDtTmTS`) order by hora;\n--Vemos a que horas se producen más accidentes."],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["%sql SELECT NeighborhoodDistrict,count(`NeighborhoodDistrict`) FROM fireServiceVIEW WHERE dayofyear(`CallDateTS`)=1 AND CallType LIKE 'Traffic Collision' group by NeighborhoodDistrict order by count(`NeighborhoodDistrict`) desc ;\n--Vemos en que barrios se producen más accidentes en año nuevo "],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["%sql SELECT distinct hour(`ReceivedDtTmTS`) as hora, count( hour(`ReceivedDtTmTS`)) as cuenta FROM fireServiceVIEW WHERE year(`CallDateTS`)==2016 AND dayofyear(`CallDateTS`)=37 group by hour(`ReceivedDtTmTS`) order by cuenta DESC;\n--Vemos a que hora se registraron más llamadas el día 37"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["%sql SELECT distinct hour(`ReceivedDtTmTS`) as hora, count( hour(`ReceivedDtTmTS`)) as cuenta FROM fireServiceVIEW WHERE year(`CallDateTS`)==2016 group by hour(`ReceivedDtTmTS`) order by cuenta DESC;\n--Mostramos a que horas se suelen producir más llamadas durante 2016 para comparar los resultados"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["#Vemos los barrios con mas llamadas\nspark.sql(\"SELECT `NeighborhoodDistrict`, count(`NeighborhoodDistrict`) AS Neighborhood_Count FROM fireServiceVIEW WHERE year(`CallDateTS`) == '2016' GROUP BY `NeighborhoodDistrict` ORDER BY Neighborhood_Count DESC LIMIT 15\").show()"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["#Creamos un nuevo data frame renombrando algunas columnas\nincidentsDF = spark.read.csv('/mnt/sf_open_data/fire_incidents/Fire_Incidents.csv', header=True, inferSchema=True).withColumnRenamed('Incident Number', 'IncidentNumber').withColumnRenamed('Neighborhood  District', 'NeighborhoodDistrictIncident').withColumnRenamed('Primary Situation','PrimarySituationIncident').cache()\n"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["#Vemos que efectivamente se han renombrado\ndisplay(incidentsDF.limit(3))"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["#Mostramos el esquema del nuevo df\nincidentsDF.printSchema()"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["# Materializamos el cache\nincidentsDF.count()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["joinedDF = myDF.join(incidentsDF, myDF.IncidentNumber == incidentsDF.IncidentNumber)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["display(joinedDF.limit(3))"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["joinedDF.count()"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["joinedDF.filter(year('CallDateTS') == '2016').filter(col('NeighborhoodDistrict') == 'Tenderloin').count()"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["#Mostramos los tipos de llamada mas realizados en Tenderloin en 2016\ndisplay(joinedDF.filter(year('CallDateTS') == '2016').filter(col('NeighborhoodDistrict') == 'Tenderloin').groupBy('PrimarySituationIncident').count().orderBy(desc(\"count\")).limit(100))"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["#Mostramos los barrios donde se producen más llamdas falsas\ndisplay(joinedDF.filter(year('CallDateTS') == '2016').filter(col('PrimarySituationIncident') == '700 false alarm or false call, other').groupBy('NeighborhoodDistrict').count().orderBy(desc(\"count\")).limit(10))"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["display(joinedDF.select('CallType').filter(year('CallDateTS') == '2016').filter(col('PrimarySituationIncident') == '700 false alarm or false call, other').groupBy('CallType').count().orderBy(desc(\"count\")))"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["#Mostramos de que tipo son las llamadas en Russian Hill limitado a 100\ndisplay(joinedDF.filter(year('CallDateTS') == '2016').filter(col('NeighborhoodDistrict') == 'Russian Hill').limit(100))"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["#Tipos de llamadas en el zip 94132.0 -por brotherhood, Ingleside Heights-\ndisplay(joinedDF.filter(year('CallDateTS') == '2016').filter(col('ZipcodeofIncident') == '94132.0').limit(100))"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["import pandas as pd"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["#Convertimos los datos del dataframe a pandas cuyo año sea 2016\npandasDF = joinedDF.filter(year('CallDateTS')=='2016').toPandas()"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["from pyspark.sql.types import *\n"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["import numpy as np\n"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["from sklearn.cross_validation import train_test_split\n"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["pandasDF.columns"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["joinedDF.columns"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["#Decidimos los features de nuestro modelo en este caso el tipo de llamada, el codigo postal, la prioridad original de la llamada, la prioridad final de la llamada y por último la zona\nfeatures = [3,7,11,13,21]\n\n"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["X = pandasDF.iloc[:,features]\n#La Y a predecir será Call type Group\nY= pandasDF.iloc[:,15]\n"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["print(Y)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["from sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["X_values = X.values\nY_values = Y.values"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["le = preprocessing.LabelEncoder()"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["#Etiquetamos la Y\ny_encoded =le.fit_transform(Y_values)"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["print(y_encoded)"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["print(X_values)"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["#Codificamos a numero los inputs de la X\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nle = preprocessing.LabelEncoder()\nX_encoded=X_values\nfor i in range(len(X_values)):\n  X_encoded[i]=le.fit_transform(X_values[i])\n"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["print(X_encoded)"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["#Dividimos todos los datos en train y test dejando un 20% para el test \nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size = .2)"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["from sklearn import tree\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["#Creamos el RandomForestClassifier\nclf = RandomForestClassifier(n_jobs=4,random_state=0,n_estimators=100, verbose=0, max_features=5, max_depth=4)"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"code","source":["#Entrenamos el modelo\nclf.fit(X_train, y_train)"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["np.set_printoptions(threshold=np.nan)\nnp.set_printoptions(threshold='nan')"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["#Predecimos todos los datos de test\nfrom sklearn.metrics import accuracy_score\npreds = clf.predict(X_test)\n#Imprimimos el porcentaje de acierto del modelo \nprint (accuracy_score(y_test, preds))"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import roc_auc_score"],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":["#Predecimos una muestra solamente\n#Ejemplo Alarma = 4,0,2,1,3 \n#Ejemplo Fuego = 3,0,2,1,3\n#Ejemplo No Riesgo Muerte = 0,2,3,1,4\n#Ejemplo Riesgo Muerte = 0,2,3,1,2\npred1=clf.predict([0,2,3,1,2])\nprint(pred1)\npredd=\"a\"\nif pred1==1:\n  print(pred1)\n  predd=\"Alarma\"\nelif pred1==2:\n  predd=\"Incendio\"\nelif pred1==3:\n  predd=\"No riesgo de muerte\"\nelif pred1==4:\n  predd=\"Situación con riesgo potencial de muerte\"\nprint(predd)"],"metadata":{},"outputs":[],"execution_count":90}],"metadata":{"name":"TFG-Run","notebookId":4293251168139579},"nbformat":4,"nbformat_minor":0}
